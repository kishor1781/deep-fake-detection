{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check for GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"Num GPUs Available: {len(gpus)}\")\n",
    "else:\n",
    "    print(\"No GPU available. Using CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_HOME = r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"Num GPUs Available: {len(gpus)}\")\n",
    "    for gpu in gpus:\n",
    "        print(gpu)\n",
    "else:\n",
    "    print(\"No GPU available. Using CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"Num GPUs Available: {len(gpus)}\")\n",
    "    for gpu in gpus:\n",
    "        print(gpu)\n",
    "else:\n",
    "    print(\"No GPU available. Using CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_videos_path = r'C:\\Users\\manik\\Documents\\devhack\\deepfake\\data\\Celeb-real'\n",
    "fake_videos_path = r'C:\\Users\\manik\\Documents\\devhack\\deepfake\\data\\Celeb-synthesis'\n",
    "youtube_videos_path = r'C:\\Users\\manik\\Documents\\devhack\\deepfake\\data\\YouTube-real'\n",
    "\n",
    "# Video listing\n",
    "real_videos = [os.path.join(real_videos_path, video) for video in os.listdir(real_videos_path)]\n",
    "fake_videos = [os.path.join(fake_videos_path, video) for video in os.listdir(fake_videos_path)]\n",
    "youtube_videos = [os.path.join(youtube_videos_path, video) for video in os.listdir(youtube_videos_path)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_paths = real_videos + fake_videos + youtube_videos\n",
    "labels = [0] * len(real_videos) + [1] * len(fake_videos) + [0] * len(youtube_videos)\n",
    "\n",
    "df = pd.DataFrame({'video_path': video_paths, 'label': labels})\n",
    "\n",
    "# Data splitting\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10, 112, 112, 3)  0         \n",
      "                             ]                                   \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 10, 110, 110, 64)  1792     \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 10, 55, 55, 64)   0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 10, 193600)       0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 10, 128)           99189248  \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 99,244,673\n",
      "Trainable params: 99,244,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def extract_frames(video_path, num_frames=30):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    count = 0\n",
    "\n",
    "    while cap.isOpened() and count < num_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (112, 112))\n",
    "        frames.append(frame)\n",
    "        count += 1\n",
    "\n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "# LSTM model\n",
    "def build_lstm_model(num_frames=10):\n",
    "    input_layer = layers.Input(shape=(num_frames, 112, 112, 3))\n",
    "\n",
    "    x = layers.TimeDistributed(layers.Conv2D(64, (3, 3), activation='relu'))(input_layer)\n",
    "    x = layers.TimeDistributed(layers.MaxPooling2D((2, 2)))(x)\n",
    "    x = layers.TimeDistributed(layers.Flatten())(x)\n",
    "\n",
    "    x = layers.LSTM(128, return_sequences=True)(x)\n",
    "    x = layers.LSTM(64, return_sequences=False)(x)\n",
    "\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    output_layer = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Build model\n",
    "lstm_model = build_lstm_model(num_frames=10)\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  30/1175 [..............................] - ETA: 37:01 - loss: 0.4383 - accuracy: 0.8667"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 43\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mlstm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_df\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# Save model\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     model_save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\manik\\Documents\\devhack\\deepfake\\deepfake_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\manik\\Documents\\devhack\\deepfake\\deepfake_env\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\manik\\Documents\\devhack\\deepfake\\deepfake_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\manik\\Documents\\devhack\\deepfake\\deepfake_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\manik\\Documents\\devhack\\deepfake\\deepfake_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\manik\\Documents\\devhack\\deepfake\\deepfake_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\manik\\Documents\\devhack\\deepfake\\deepfake_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\manik\\Documents\\devhack\\deepfake\\deepfake_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\manik\\Documents\\devhack\\deepfake\\deepfake_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def data_generator(df, batch_size, num_frames=10):\n",
    "    num_samples = len(df)\n",
    "    while True:\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = df.iloc[offset:offset + batch_size]\n",
    "            video_sequences = []\n",
    "            labels = []\n",
    "\n",
    "            for _, row in batch_samples.iterrows():\n",
    "                video_path = row['video_path']\n",
    "                label = row['label']\n",
    "                frames = []\n",
    "\n",
    "                cap = cv2.VideoCapture(video_path)\n",
    "                frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "                for i in np.linspace(0, frame_count - 1, num_frames, dtype=int):\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "                    ret, frame = cap.read()\n",
    "                    if ret:\n",
    "                        frame = cv2.resize(frame, (112, 112))\n",
    "                        frames.append(frame)\n",
    "                    else:\n",
    "                        frames.append(np.zeros((112, 112, 3)))\n",
    "\n",
    "                cap.release()\n",
    "                video_sequences.append(np.array(frames))\n",
    "                labels.append(label)\n",
    "\n",
    "            X = np.array(video_sequences)\n",
    "            y = np.array(labels)\n",
    "            yield X, y\n",
    "\n",
    "# Training\n",
    "batch_size = 4  # Increase batch size for GPU training\n",
    "num_frames = 10\n",
    "\n",
    "train_gen = data_generator(train_df, batch_size=batch_size, num_frames=num_frames)\n",
    "val_gen = data_generator(val_df, batch_size=batch_size, num_frames=num_frames)\n",
    "\n",
    "# Train model\n",
    "try:\n",
    "    history = lstm_model.fit(\n",
    "        train_gen,\n",
    "        steps_per_epoch=len(train_df) // batch_size,\n",
    "        validation_data=val_gen,\n",
    "        validation_steps=len(val_df) // batch_size,\n",
    "        epochs=10,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Save model\n",
    "    model_save_path = 'lstm_model.h5'\n",
    "    lstm_model.save(model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during model training: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create a validation generator\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m val_gen \u001b[38;5;241m=\u001b[39m \u001b[43mdata_generator\u001b[49m(val_df, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, num_frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m lstm_model\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m      6\u001b[0m     val_gen,\n\u001b[0;32m      7\u001b[0m     steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(val_df) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size,\n\u001b[0;32m      8\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_generator' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a validation generator\n",
    "val_gen = data_generator(val_df, batch_size=batch_size, num_frames=10)\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_accuracy = lstm_model.evaluate(\n",
    "    val_gen,\n",
    "    steps=len(val_df) // batch_size,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f'Validation Loss: {val_loss}')\n",
    "print(f'Validation Accuracy: {val_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model\n",
    "model_path = 'lstm_model.h5'\n",
    "lstm_model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 56s 426ms/step - loss: 0.3841 - accuracy: 0.8712\n",
      "Validation Loss: 0.3841301500797272\n",
      "Validation Accuracy: 0.8711538314819336\n"
     ]
    }
   ],
   "source": [
    "# Create a validation generator\n",
    "val_gen = data_generator(val_df, batch_size=batch_size, num_frames=10)\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_accuracy = lstm_model.evaluate(\n",
    "    val_gen,\n",
    "    steps=len(val_df) // batch_size,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f'Validation Loss: {val_loss}')\n",
    "print(f'Validation Accuracy: {val_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 847ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 225ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "1/1 [==============================] - 1s 771ms/step\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 225ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        67\n",
      "           1       0.87      1.00      0.93       453\n",
      "\n",
      "    accuracy                           0.87       520\n",
      "   macro avg       0.44      0.50      0.47       520\n",
      "weighted avg       0.76      0.87      0.81       520\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manik\\Documents\\devhack\\deepfake\\deepfake_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manik\\Documents\\devhack\\deepfake\\deepfake_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\manik\\Documents\\devhack\\deepfake\\deepfake_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Get the true labels and predicted labels\n",
    "for _ in range(len(val_df) // batch_size):\n",
    "    X_batch, y_batch = next(val_gen)  # Get a batch of validation data\n",
    "    preds = lstm_model.predict(X_batch)\n",
    "    y_true.extend(y_batch)\n",
    "    y_pred.extend((preds > 0.5).astype(int))  # Convert probabilities to binary predictions\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.save('deepfake_detection_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 772ms/step\n",
      "The video is classified as fake.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def preprocess_video(video_path, frame_size=(112, 112), num_frames=10):\n",
    "    # Load the video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    frames = []\n",
    "    while len(frames) < num_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, frame_size)\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) < num_frames:\n",
    "        raise ValueError(f\"Not enough frames in the video. Required: {num_frames}, Found: {len(frames)}\")\n",
    "\n",
    "    # Convert to numpy array and normalize\n",
    "    frames = np.array(frames).astype('float32') / 255.0\n",
    "    \n",
    "    # Expand dimensions to match input shape (1, num_frames, height, width, channels)\n",
    "    frames = np.expand_dims(frames, axis=0)\n",
    "\n",
    "    return frames\n",
    "\n",
    "# Load the previously saved model\n",
    "model_path = 'C:\\\\Users\\\\manik\\\\Documents\\\\devhack\\\\deepfake\\\\deepfake_detection_model.h5'\n",
    "lstm_model = load_model(model_path)\n",
    "\n",
    "# Path to your video file\n",
    "video_path = r\"C:\\Users\\manik\\Documents\\devhack\\deepfake\\data\\YouTube-real\\00000.mp4\"\n",
    "\n",
    "try:\n",
    "    # Preprocess the video\n",
    "    input_frames = preprocess_video(video_path)\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction = lstm_model.predict(input_frames)\n",
    "\n",
    "    # Interpret the prediction\n",
    "    if prediction[0][0] > 0.5:\n",
    "        print(\"The video is classified as fake.\")\n",
    "    else:\n",
    "        print(\"The video is classified as real.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "except ValueError as ve:\n",
    "    print(ve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 613ms/step\n",
      "The video is classified as fake with confidence 0.87.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def preprocess_video(video_path, frame_size=(112, 112), num_frames=10):\n",
    "    \"\"\"\n",
    "    Preprocess a video by extracting frames, resizing them, and normalizing the pixel values.\n",
    "    \n",
    "    Args:\n",
    "    video_path (str): The path to the video file.\n",
    "    frame_size (tuple): The desired frame size for the model input.\n",
    "    num_frames (int): The number of frames to extract from the video.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: A numpy array of shape (1, num_frames, height, width, channels)\n",
    "                containing the preprocessed video frames.\n",
    "    \"\"\"\n",
    "    # Open the video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    frames = []\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Calculate frame indices to capture evenly distributed frames\n",
    "    frame_indices = np.linspace(0, total_frames - 1, num_frames).astype(int)\n",
    "    \n",
    "    for i in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, frame_size)\n",
    "            frames.append(frame)\n",
    "        else:\n",
    "            frames.append(np.zeros((frame_size[0], frame_size[1], 3)))  # Add zero frames if not enough frames\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) < num_frames:\n",
    "        raise ValueError(f\"Not enough frames in the video. Required: {num_frames}, Found: {len(frames)}\")\n",
    "\n",
    "    # Convert to numpy array and normalize pixel values to range [0, 1]\n",
    "    frames = np.array(frames).astype('float32') / 255.0\n",
    "    \n",
    "    # Expand dimensions to match input shape (1, num_frames, height, width, channels)\n",
    "    frames = np.expand_dims(frames, axis=0)\n",
    "\n",
    "    return frames\n",
    "\n",
    "# Load the saved model\n",
    "model_path = r'C:\\Users\\manik\\Documents\\devhack\\deepfake\\lstm_model.h5'\n",
    "lstm_model = load_model(model_path)\n",
    "\n",
    "# Path to the video file for prediction\n",
    "video_path = r\"C:\\Users\\manik\\OneDrive\\Desktop\\amir khan.mp4\"\n",
    "\n",
    "try:\n",
    "    # Preprocess the video\n",
    "    input_frames = preprocess_video(video_path)\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction = lstm_model.predict(input_frames)\n",
    "\n",
    "    # Interpret the prediction (threshold = 0.5)\n",
    "    if prediction[0][0] > 0.5:\n",
    "        print(f\"The video is classified as fake with confidence {prediction[0][0]:.2f}.\")\n",
    "    else:\n",
    "        print(f\"The video is classified as real with confidence {1 - prediction[0][0]:.2f}.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found: {e}\")\n",
    "except ValueError as ve:\n",
    "    print(f\"Value Error: {ve}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfake_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
